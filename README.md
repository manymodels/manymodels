_tl;dr_ Many communities benefit from a world with many AI models. Let's do research, write specifications, and build software in order to make that world more likely.

**Many models** describes a world with many AI models, including the large private models extant today as well as open-source models, public models, foundation models, narrow models, large language models, text-to-image models, and models running on edge or decentralized infrastructure.

Many models is also an **open research program** intended to explore, specify, and build infrastructure for a world of many models. This program poses a range of research questions—and organizes a number of research projects—across transfer learning, metalearning, ensemble methods, differentiable games, computational learning theory, ML and data engineering, data mining, data integration, networking, cryptography, and protocol design, as well as questions in data licensing, data governance, AI governance, and institutional design.

# In this repo
This repository organizes a research program, including research questions and a (soon-to-come) regular research seminar. 

Currently, our research questions are organized into three “layers”: 
- a model layer, covering interactions between many models
- a data layer, covering sharing, transmission, and management of aggregate data sets
- a world layer, covering applications, processes, and institutions through which data is generated and then published on the internet

These layers should not be treated as a specification for many models; for the moment, they are simply ways of organizing research questions.

Note: we do *not* assume that many models are better than few models or one model, but we are committed to exploring and building up the value of many models.
